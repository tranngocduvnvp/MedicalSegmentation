{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using StepLR\n",
      "best test: None epoch: 0\n",
      "Train Epoch: 1 [544/562 (100.0%)]\tAverage loss: 1.218094\tTime: 3.732412\n",
      "Val  Epoch: 1 [71/71 (100.0%)]\tDice: 0.482772\tmIOU: 0.355046\tPrecision: 0.931999\tRecall: 0.360230\tF1_score: 0.482772\tTime: 0.742145\n",
      "\u001b[1m========== Test ==============\u001b[0m\n",
      "\u001b[44m\u001b[37mNormal\u001b[0m\n",
      "Test  Epoch: 1 [71/71 (100.0%)]\tDice: 0.386007\tmIOU: 0.276881\tPrecision: 0.904645\tRecall: 0.282857\tTime: 0.642229\n",
      "\u001b[43m\u001b[30mAbNormal\u001b[0m\n",
      "Test  Epoch: 1 [71/71 (100.0%)]\tDice: 0.572866\tmIOU: 0.439363\tPrecision: 0.915992\tRecall: 0.449152\tTime: 0.642280\n",
      "\u001b[42m\u001b[31mAverage\u001b[0m\n",
      "Test  Epoch: 1 [71/71 (100.0%)]\tDice: 0.478121\tmIOU: 0.356978\tPrecision: 0.910239\tRecall: 0.364833\tTime: 0.642328\n",
      "\u001b[41m\u001bSaving.....................\u001b[0m\n",
      "Train Epoch: 2 [544/562 (100.0%)]\tAverage loss: 1.155026\tTime: 3.180028\n",
      "Val  Epoch: 2 [71/71 (100.0%)]\tDice: 0.105332\tmIOU: 0.061918\tPrecision: 0.535211\tRecall: 0.061918\tF1_score: 0.105332\tTime: 0.710831\n",
      "\u001b[1m========== Test ==============\u001b[0m\n",
      "\u001b[44m\u001b[37mNormal\u001b[0m\n",
      "Test  Epoch: 2 [71/71 (100.0%)]\tDice: 0.085562\tmIOU: 0.050290\tPrecision: 0.361111\tRecall: 0.050290\tTime: 0.664029\n",
      "\u001b[43m\u001b[30mAbNormal\u001b[0m\n",
      "Test  Epoch: 2 [71/71 (100.0%)]\tDice: 0.127179\tmIOU: 0.073195\tPrecision: 0.657143\tRecall: 0.073195\tTime: 0.664080\n",
      "\u001b[42m\u001b[31mAverage\u001b[0m\n",
      "Test  Epoch: 2 [71/71 (100.0%)]\tDice: 0.106078\tmIOU: 0.061582\tPrecision: 0.507042\tRecall: 0.061582\tTime: 0.664128\n",
      "Train Epoch: 3 [544/562 (100.0%)]\tAverage loss: 0.996191\tTime: 3.168318\n",
      "Val  Epoch: 3 [71/71 (100.0%)]\tDice: 0.708643\tmIOU: 0.562766\tPrecision: 0.975897\tRecall: 0.571631\tF1_score: 0.708643\tTime: 0.723460\n",
      "\u001b[1m========== Test ==============\u001b[0m\n",
      "\u001b[44m\u001b[37mNormal\u001b[0m\n",
      "Test  Epoch: 3 [71/71 (100.0%)]\tDice: 0.676542\tmIOU: 0.525171\tPrecision: 0.953507\tRecall: 0.539987\tTime: 0.708597\n",
      "\u001b[43m\u001b[30mAbNormal\u001b[0m\n",
      "Test  Epoch: 3 [71/71 (100.0%)]\tDice: 0.739381\tmIOU: 0.606502\tPrecision: 0.971218\tRecall: 0.622082\tTime: 0.708648\n",
      "\u001b[42m\u001b[31mAverage\u001b[0m\n",
      "Test  Epoch: 3 [71/71 (100.0%)]\tDice: 0.707519\tmIOU: 0.565263\tPrecision: 0.962238\tRecall: 0.580457\tTime: 0.708696\n",
      "\u001b[41m\u001bSaving.....................\u001b[0m\n",
      "Train Epoch: 4 [544/562 (100.0%)]\tAverage loss: 0.817619\tTime: 3.299895\n",
      "Val  Epoch: 4 [71/71 (100.0%)]\tDice: 0.830436\tmIOU: 0.717001\tPrecision: 0.889834\tRecall: 0.793253\tF1_score: 0.830436\tTime: 0.676414\n",
      "\u001b[1m========== Test ==============\u001b[0m\n",
      "\u001b[44m\u001b[37mNormal\u001b[0m\n",
      "Test  Epoch: 4 [71/71 (100.0%)]\tDice: 0.806445\tmIOU: 0.682765\tPrecision: 0.848775\tRecall: 0.788600\tTime: 0.666171\n",
      "\u001b[43m\u001b[30mAbNormal\u001b[0m\n",
      "Test  Epoch: 4 [71/71 (100.0%)]\tDice: 0.844059\tmIOU: 0.735872\tPrecision: 0.893251\tRecall: 0.820014\tTime: 0.666222\n",
      "\u001b[42m\u001b[31mAverage\u001b[0m\n",
      "Test  Epoch: 4 [71/71 (100.0%)]\tDice: 0.824987\tmIOU: 0.708944\tPrecision: 0.870700\tRecall: 0.804086\tTime: 0.666270\n",
      "\u001b[41m\u001bSaving.....................\u001b[0m\n",
      "Train Epoch: 5 [544/562 (100.0%)]\tAverage loss: 0.773236\tTime: 3.187337\n",
      "Val  Epoch: 5 [71/71 (100.0%)]\tDice: 0.840419\tmIOU: 0.730993\tPrecision: 0.874623\tRecall: 0.820728\tF1_score: 0.840419\tTime: 0.688123\n",
      "\u001b[1m========== Test ==============\u001b[0m\n",
      "\u001b[44m\u001b[37mNormal\u001b[0m\n",
      "Test  Epoch: 5 [71/71 (100.0%)]\tDice: 0.816456\tmIOU: 0.697919\tPrecision: 0.833170\tRecall: 0.818330\tTime: 0.661921\n",
      "\u001b[43m\u001b[30mAbNormal\u001b[0m\n",
      "Test  Epoch: 5 [71/71 (100.0%)]\tDice: 0.857064\tmIOU: 0.753321\tPrecision: 0.880865\tRecall: 0.848808\tTime: 0.661971\n",
      "\u001b[42m\u001b[31mAverage\u001b[0m\n",
      "Test  Epoch: 5 [71/71 (100.0%)]\tDice: 0.836474\tmIOU: 0.725230\tPrecision: 0.856682\tRecall: 0.833354\tTime: 0.662017\n",
      "\u001b[41m\u001bSaving.....................\u001b[0m\n",
      "Train Epoch: 6 [544/562 (100.0%)]\tAverage loss: 0.693401\tTime: 3.231896\n",
      "Val  Epoch: 6 [71/71 (100.0%)]\tDice: 0.846423\tmIOU: 0.738010\tPrecision: 0.796784\tRecall: 0.915509\tF1_score: 0.846423\tTime: 0.753164\n",
      "\u001b[1m========== Test ==============\u001b[0m\n",
      "\u001b[44m\u001b[37mNormal\u001b[0m\n",
      "Test  Epoch: 6 [71/71 (100.0%)]\tDice: 0.815389\tmIOU: 0.697838\tPrecision: 0.751519\tRecall: 0.917749\tTime: 0.696247\n",
      "\u001b[43m\u001b[30mAbNormal\u001b[0m\n",
      "Test  Epoch: 6 [71/71 (100.0%)]\tDice: 0.852125\tmIOU: 0.743988\tPrecision: 0.795102\tRecall: 0.927463\tTime: 0.696297\n",
      "\u001b[42m\u001b[31mAverage\u001b[0m\n",
      "Test  Epoch: 6 [71/71 (100.0%)]\tDice: 0.833498\tmIOU: 0.720588\tPrecision: 0.773004\tRecall: 0.922538\tTime: 0.696344\n",
      "\u001b[41m\u001bSaving.....................\u001b[0m\n",
      "Train Epoch: 7 [544/562 (100.0%)]\tAverage loss: 0.683424\tTime: 3.180676\n",
      "Val  Epoch: 7 [71/71 (100.0%)]\tDice: 0.871025\tmIOU: 0.775660\tPrecision: 0.871191\tRecall: 0.880710\tF1_score: 0.871025\tTime: 0.668241\n",
      "\u001b[1m========== Test ==============\u001b[0m\n",
      "\u001b[44m\u001b[37mNormal\u001b[0m\n",
      "Test  Epoch: 7 [71/71 (100.0%)]\tDice: 0.847134\tmIOU: 0.742522\tPrecision: 0.831879\tRecall: 0.882488\tTime: 0.649249\n",
      "\u001b[43m\u001b[30mAbNormal\u001b[0m\n",
      "Test  Epoch: 7 [71/71 (100.0%)]\tDice: 0.877431\tmIOU: 0.783676\tPrecision: 0.863356\tRecall: 0.901139\tTime: 0.649301\n",
      "\u001b[42m\u001b[31mAverage\u001b[0m\n",
      "Test  Epoch: 7 [71/71 (100.0%)]\tDice: 0.862070\tmIOU: 0.762809\tPrecision: 0.847396\tRecall: 0.891682\tTime: 0.649348\n",
      "\u001b[41m\u001bSaving.....................\u001b[0m\n",
      "Train Epoch: 8 [544/562 (100.0%)]\tAverage loss: 0.654348\tTime: 3.403559\n",
      "Val  Epoch: 8 [71/71 (100.0%)]\tDice: 0.858457\tmIOU: 0.757231\tPrecision: 0.950889\tRecall: 0.790105\tF1_score: 0.858457\tTime: 0.679110\n",
      "\u001b[1m========== Test ==============\u001b[0m\n",
      "\u001b[44m\u001b[37mNormal\u001b[0m\n",
      "Test  Epoch: 8 [71/71 (100.0%)]\tDice: 0.846604\tmIOU: 0.738821\tPrecision: 0.927349\tRecall: 0.789237\tTime: 0.655912\n",
      "\u001b[43m\u001b[30mAbNormal\u001b[0m\n",
      "Test  Epoch: 8 [71/71 (100.0%)]\tDice: 0.872985\tmIOU: 0.780398\tPrecision: 0.947294\tRecall: 0.819517\tTime: 0.655962\n",
      "\u001b[42m\u001b[31mAverage\u001b[0m\n",
      "Test  Epoch: 8 [71/71 (100.0%)]\tDice: 0.859609\tmIOU: 0.759317\tPrecision: 0.937181\tRecall: 0.804164\tTime: 0.656010\n",
      "Train Epoch: 9 [544/562 (100.0%)]\tAverage loss: 0.649980\tTime: 3.192245\n",
      "Val  Epoch: 9 [71/71 (100.0%)]\tDice: 0.841417\tmIOU: 0.737485\tPrecision: 0.919355\tRecall: 0.792915\tF1_score: 0.841417\tTime: 0.743012\n",
      "\u001b[1m========== Test ==============\u001b[0m\n",
      "\u001b[44m\u001b[37mNormal\u001b[0m\n",
      "Test  Epoch: 9 [71/71 (100.0%)]\tDice: 0.819860\tmIOU: 0.705165\tPrecision: 0.886576\tRecall: 0.780729\tTime: 0.654898\n",
      "\u001b[43m\u001b[30mAbNormal\u001b[0m\n",
      "Test  Epoch: 9 [71/71 (100.0%)]\tDice: 0.855643\tmIOU: 0.759605\tPrecision: 0.923703\tRecall: 0.821426\tTime: 0.654947\n",
      "\u001b[42m\u001b[31mAverage\u001b[0m\n",
      "Test  Epoch: 9 [71/71 (100.0%)]\tDice: 0.837499\tmIOU: 0.732002\tPrecision: 0.904878\tRecall: 0.800791\tTime: 0.654993\n",
      "Train Epoch: 10 [544/562 (100.0%)]\tAverage loss: 0.627679\tTime: 3.214851\n",
      "Val  Epoch: 10 [71/71 (100.0%)]\tDice: 0.880240\tmIOU: 0.790618\tPrecision: 0.936345\tRecall: 0.838531\tF1_score: 0.880240\tTime: 0.714782\n",
      "\u001b[1m========== Test ==============\u001b[0m\n",
      "\u001b[44m\u001b[37mNormal\u001b[0m\n",
      "Test  Epoch: 10 [71/71 (100.0%)]\tDice: 0.866156\tmIOU: 0.768096\tPrecision: 0.909299\tRecall: 0.837887\tTime: 0.752936\n",
      "\u001b[43m\u001b[30mAbNormal\u001b[0m\n",
      "Test  Epoch: 10 [71/71 (100.0%)]\tDice: 0.888396\tmIOU: 0.803662\tPrecision: 0.930630\tRecall: 0.859128\tTime: 0.752989\n",
      "\u001b[42m\u001b[31mAverage\u001b[0m\n",
      "Test  Epoch: 10 [71/71 (100.0%)]\tDice: 0.877119\tmIOU: 0.785628\tPrecision: 0.919814\tRecall: 0.848358\tTime: 0.753036\n",
      "\u001b[41m\u001bSaving.....................\u001b[0m\n",
      "Train Epoch: 11 [544/562 (100.0%)]\tAverage loss: 0.608751\tTime: 3.438430\n",
      "Val  Epoch: 11 [71/71 (100.0%)]\tDice: 0.894564\tmIOU: 0.812472\tPrecision: 0.887706\tRecall: 0.909030\tF1_score: 0.894564\tTime: 0.706643\n",
      "\u001b[1m========== Test ==============\u001b[0m\n",
      "\u001b[44m\u001b[37mNormal\u001b[0m\n",
      "Test  Epoch: 11 [71/71 (100.0%)]\tDice: 0.873428\tmIOU: 0.782134\tPrecision: 0.850643\tRecall: 0.912124\tTime: 0.654473\n",
      "\u001b[43m\u001b[30mAbNormal\u001b[0m\n",
      "Test  Epoch: 11 [71/71 (100.0%)]\tDice: 0.899428\tmIOU: 0.819094\tPrecision: 0.882745\tRecall: 0.923485\tTime: 0.654521\n",
      "\u001b[42m\u001b[31mAverage\u001b[0m\n",
      "Test  Epoch: 11 [71/71 (100.0%)]\tDice: 0.886245\tmIOU: 0.800354\tPrecision: 0.866468\tRecall: 0.917724\tTime: 0.654567\n",
      "\u001b[41m\u001bSaving.....................\u001b[0m\n",
      "Train Epoch: 12 [544/562 (100.0%)]\tAverage loss: 0.597576\tTime: 3.202367\n",
      "Val  Epoch: 12 [71/71 (100.0%)]\tDice: 0.901347\tmIOU: 0.823415\tPrecision: 0.905647\tRecall: 0.903382\tF1_score: 0.901347\tTime: 0.682052\n",
      "\u001b[1m========== Test ==============\u001b[0m\n",
      "\u001b[44m\u001b[37mNormal\u001b[0m\n",
      "Test  Epoch: 12 [71/71 (100.0%)]\tDice: 0.884781\tmIOU: 0.798585\tPrecision: 0.874381\tRecall: 0.906183\tTime: 0.649214\n",
      "\u001b[43m\u001b[30mAbNormal\u001b[0m\n",
      "Test  Epoch: 12 [71/71 (100.0%)]\tDice: 0.906671\tmIOU: 0.831470\tPrecision: 0.898549\tRecall: 0.921350\tTime: 0.649264\n",
      "\u001b[42m\u001b[31mAverage\u001b[0m\n",
      "Test  Epoch: 12 [71/71 (100.0%)]\tDice: 0.895572\tmIOU: 0.814796\tPrecision: 0.886295\tRecall: 0.913659\tTime: 0.649311\n",
      "\u001b[41m\u001bSaving.....................\u001b[0m\n",
      "Train Epoch: 13 [544/562 (100.0%)]\tAverage loss: 0.589159\tTime: 3.264882\n",
      "Val  Epoch: 13 [71/71 (100.0%)]\tDice: 0.895381\tmIOU: 0.813705\tPrecision: 0.869356\tRecall: 0.930425\tF1_score: 0.895381\tTime: 0.708042\n",
      "\u001b[1m========== Test ==============\u001b[0m\n",
      "\u001b[44m\u001b[37mNormal\u001b[0m\n",
      "Test  Epoch: 13 [71/71 (100.0%)]\tDice: 0.877079\tmIOU: 0.787264\tPrecision: 0.836681\tRecall: 0.935056\tTime: 0.712136\n",
      "\u001b[43m\u001b[30mAbNormal\u001b[0m\n",
      "Test  Epoch: 13 [71/71 (100.0%)]\tDice: 0.895626\tmIOU: 0.812850\tPrecision: 0.859507\tRecall: 0.942301\tTime: 0.712187\n",
      "\u001b[42m\u001b[31mAverage\u001b[0m\n",
      "Test  Epoch: 13 [71/71 (100.0%)]\tDice: 0.886222\tmIOU: 0.799877\tPrecision: 0.847933\tRecall: 0.938627\tTime: 0.712235\n",
      "Train Epoch: 14 [544/562 (100.0%)]\tAverage loss: 0.566841\tTime: 3.221597\n",
      "Val  Epoch: 14 [71/71 (100.0%)]\tDice: 0.901905\tmIOU: 0.824557\tPrecision: 0.931776\tRecall: 0.879984\tF1_score: 0.901905\tTime: 0.659805\n",
      "\u001b[1m========== Test ==============\u001b[0m\n",
      "\u001b[44m\u001b[37mNormal\u001b[0m\n",
      "Test  Epoch: 14 [71/71 (100.0%)]\tDice: 0.889779\tmIOU: 0.805188\tPrecision: 0.904898\tRecall: 0.884017\tTime: 0.687954\n",
      "\u001b[43m\u001b[30mAbNormal\u001b[0m\n",
      "Test  Epoch: 14 [71/71 (100.0%)]\tDice: 0.905454\tmIOU: 0.830234\tPrecision: 0.921960\tRecall: 0.896077\tTime: 0.688006\n",
      "\u001b[42m\u001b[31mAverage\u001b[0m\n",
      "Test  Epoch: 14 [71/71 (100.0%)]\tDice: 0.897506\tmIOU: 0.817534\tPrecision: 0.913309\tRecall: 0.889962\tTime: 0.688055\n",
      "\u001b[41m\u001bSaving.....................\u001b[0m\n",
      "Train Epoch: 15 [544/562 (100.0%)]\tAverage loss: 0.560352\tTime: 3.324204\n",
      "Val  Epoch: 15 [71/71 (100.0%)]\tDice: 0.906591\tmIOU: 0.832249\tPrecision: 0.885466\tRecall: 0.935396\tF1_score: 0.906591\tTime: 0.684527\n",
      "\u001b[1m========== Test ==============\u001b[0m\n",
      "\u001b[44m\u001b[37mNormal\u001b[0m\n",
      "Test  Epoch: 15 [71/71 (100.0%)]\tDice: 0.887581\tmIOU: 0.804972\tPrecision: 0.849971\tRecall: 0.941804\tTime: 0.648850\n",
      "\u001b[43m\u001b[30mAbNormal\u001b[0m\n",
      "Test  Epoch: 15 [71/71 (100.0%)]\tDice: 0.906657\tmIOU: 0.830961\tPrecision: 0.876982\tRecall: 0.944393\tTime: 0.648900\n",
      "\u001b[42m\u001b[31mAverage\u001b[0m\n",
      "Test  Epoch: 15 [71/71 (100.0%)]\tDice: 0.896985\tmIOU: 0.817784\tPrecision: 0.863286\tRecall: 0.943080\tTime: 0.648945\n",
      "\u001b[41m\u001bSaving.....................\u001b[0m\n",
      "Train Epoch: 16 [544/562 (100.0%)]\tAverage loss: 0.563180\tTime: 3.179940\n",
      "Val  Epoch: 16 [71/71 (100.0%)]\tDice: 0.904511\tmIOU: 0.828209\tPrecision: 0.886459\tRecall: 0.928765\tF1_score: 0.904511\tTime: 0.694220\n",
      "\u001b[1m========== Test ==============\u001b[0m\n",
      "\u001b[44m\u001b[37mNormal\u001b[0m\n",
      "Test  Epoch: 16 [71/71 (100.0%)]\tDice: 0.885544\tmIOU: 0.799950\tPrecision: 0.853032\tRecall: 0.930577\tTime: 0.665339\n",
      "\u001b[43m\u001b[30mAbNormal\u001b[0m\n",
      "Test  Epoch: 16 [71/71 (100.0%)]\tDice: 0.904981\tmIOU: 0.828151\tPrecision: 0.877965\tRecall: 0.939943\tTime: 0.665389\n",
      "\u001b[42m\u001b[31mAverage\u001b[0m\n",
      "Test  Epoch: 16 [71/71 (100.0%)]\tDice: 0.895125\tmIOU: 0.813852\tPrecision: 0.865323\tRecall: 0.935194\tTime: 0.665435\n",
      "Train Epoch: 17 [544/562 (100.0%)]\tAverage loss: 0.536525\tTime: 3.236179\n",
      "Val  Epoch: 17 [71/71 (100.0%)]\tDice: 0.911112\tmIOU: 0.839647\tPrecision: 0.926502\tRecall: 0.901838\tF1_score: 0.911112\tTime: 0.669709\n",
      "\u001b[1m========== Test ==============\u001b[0m\n",
      "\u001b[44m\u001b[37mNormal\u001b[0m\n",
      "Test  Epoch: 17 [71/71 (100.0%)]\tDice: 0.897733\tmIOU: 0.818303\tPrecision: 0.897939\tRecall: 0.905838\tTime: 0.716742\n",
      "\u001b[43m\u001b[30mAbNormal\u001b[0m\n",
      "Test  Epoch: 17 [71/71 (100.0%)]\tDice: 0.909698\tmIOU: 0.837240\tPrecision: 0.915617\tRecall: 0.910344\tTime: 0.716793\n",
      "\u001b[42m\u001b[31mAverage\u001b[0m\n",
      "Test  Epoch: 17 [71/71 (100.0%)]\tDice: 0.903631\tmIOU: 0.827638\tPrecision: 0.906653\tRecall: 0.908060\tTime: 0.716841\n",
      "\u001b[41m\u001bSaving.....................\u001b[0m\n",
      "Train Epoch: 18 [544/562 (100.0%)]\tAverage loss: 0.527206\tTime: 3.400517\n",
      "Val  Epoch: 18 [71/71 (100.0%)]\tDice: 0.915722\tmIOU: 0.847193\tPrecision: 0.934999\tRecall: 0.902411\tF1_score: 0.915722\tTime: 0.704976\n",
      "\u001b[1m========== Test ==============\u001b[0m\n",
      "\u001b[44m\u001b[37mNormal\u001b[0m\n",
      "Test  Epoch: 18 [71/71 (100.0%)]\tDice: 0.905918\tmIOU: 0.831572\tPrecision: 0.911126\tRecall: 0.907706\tTime: 0.686856\n",
      "\u001b[43m\u001b[30mAbNormal\u001b[0m\n",
      "Test  Epoch: 18 [71/71 (100.0%)]\tDice: 0.916475\tmIOU: 0.848979\tPrecision: 0.926144\tRecall: 0.913456\tTime: 0.686908\n",
      "\u001b[42m\u001b[31mAverage\u001b[0m\n",
      "Test  Epoch: 18 [71/71 (100.0%)]\tDice: 0.911122\tmIOU: 0.840153\tPrecision: 0.918529\tRecall: 0.910540\tTime: 0.686955\n",
      "\u001b[41m\u001bSaving.....................\u001b[0m\n",
      "Train Epoch: 19 [544/562 (100.0%)]\tAverage loss: 0.517150\tTime: 3.239217\n",
      "Val  Epoch: 19 [71/71 (100.0%)]\tDice: 0.914410\tmIOU: 0.844792\tPrecision: 0.903147\tRecall: 0.931415\tF1_score: 0.914410\tTime: 0.667847\n",
      "\u001b[1m========== Test ==============\u001b[0m\n",
      "\u001b[44m\u001b[37mNormal\u001b[0m\n",
      "Test  Epoch: 19 [71/71 (100.0%)]\tDice: 0.896506\tmIOU: 0.817408\tPrecision: 0.870071\tRecall: 0.934187\tTime: 0.643272\n",
      "\u001b[43m\u001b[30mAbNormal\u001b[0m\n",
      "Test  Epoch: 19 [71/71 (100.0%)]\tDice: 0.911231\tmIOU: 0.839298\tPrecision: 0.892269\tRecall: 0.937846\tTime: 0.643334\n",
      "\u001b[42m\u001b[31mAverage\u001b[0m\n",
      "Test  Epoch: 19 [71/71 (100.0%)]\tDice: 0.903765\tmIOU: 0.828199\tPrecision: 0.881014\tRecall: 0.935991\tTime: 0.643394\n",
      "Train Epoch: 20 [544/562 (100.0%)]\tAverage loss: 0.510762\tTime: 3.244696\n",
      "Val  Epoch: 20 [71/71 (100.0%)]\tDice: 0.915033\tmIOU: 0.846246\tPrecision: 0.942325\tRecall: 0.894117\tF1_score: 0.915033\tTime: 0.709494\n",
      "\u001b[1m========== Test ==============\u001b[0m\n",
      "\u001b[44m\u001b[37mNormal\u001b[0m\n",
      "Test  Epoch: 20 [71/71 (100.0%)]\tDice: 0.906538\tmIOU: 0.832178\tPrecision: 0.919343\tRecall: 0.900172\tTime: 0.648193\n",
      "\u001b[43m\u001b[30mAbNormal\u001b[0m\n",
      "Test  Epoch: 20 [71/71 (100.0%)]\tDice: 0.914817\tmIOU: 0.846138\tPrecision: 0.934236\tRecall: 0.901870\tTime: 0.648244\n",
      "\u001b[42m\u001b[31mAverage\u001b[0m\n",
      "Test  Epoch: 20 [71/71 (100.0%)]\tDice: 0.910619\tmIOU: 0.839060\tPrecision: 0.926685\tRecall: 0.901009\tTime: 0.648292\n",
      "Train Epoch: 21 [544/562 (100.0%)]\tAverage loss: 0.500827\tTime: 3.237822\n",
      "Val  Epoch: 21 [71/71 (100.0%)]\tDice: 0.920740\tmIOU: 0.855821\tPrecision: 0.921959\tRecall: 0.924626\tF1_score: 0.920740\tTime: 0.693991\n",
      "\u001b[1m========== Test ==============\u001b[0m\n",
      "\u001b[44m\u001b[37mNormal\u001b[0m\n",
      "Test  Epoch: 21 [71/71 (100.0%)]\tDice: 0.909735\tmIOU: 0.838580\tPrecision: 0.894156\tRecall: 0.932781\tTime: 0.702714\n",
      "\u001b[43m\u001b[30mAbNormal\u001b[0m\n",
      "Test  Epoch: 21 [71/71 (100.0%)]\tDice: 0.919459\tmIOU: 0.853466\tPrecision: 0.912646\tRecall: 0.932055\tTime: 0.702766\n",
      "\u001b[42m\u001b[31mAverage\u001b[0m\n",
      "Test  Epoch: 21 [71/71 (100.0%)]\tDice: 0.914528\tmIOU: 0.845918\tPrecision: 0.903271\tRecall: 0.932423\tTime: 0.702814\n",
      "\u001b[41m\u001bSaving.....................\u001b[0m\n",
      "Train Epoch: 22 [544/562 (100.0%)]\tAverage loss: 0.496497\tTime: 3.350277\n",
      "Val  Epoch: 22 [71/71 (100.0%)]\tDice: 0.921314\tmIOU: 0.856695\tPrecision: 0.934225\tRecall: 0.913144\tF1_score: 0.921314\tTime: 0.699308\n",
      "\u001b[1m========== Test ==============\u001b[0m\n",
      "\u001b[44m\u001b[37mNormal\u001b[0m\n",
      "Test  Epoch: 22 [71/71 (100.0%)]\tDice: 0.911675\tmIOU: 0.841175\tPrecision: 0.909408\tRecall: 0.919761\tTime: 0.664890\n",
      "\u001b[43m\u001b[30mAbNormal\u001b[0m\n",
      "Test  Epoch: 22 [71/71 (100.0%)]\tDice: 0.921506\tmIOU: 0.857187\tPrecision: 0.924820\tRecall: 0.923790\tTime: 0.664940\n",
      "\u001b[42m\u001b[31mAverage\u001b[0m\n",
      "Test  Epoch: 22 [71/71 (100.0%)]\tDice: 0.916522\tmIOU: 0.849068\tPrecision: 0.917005\tRecall: 0.921747\tTime: 0.665017\n",
      "\u001b[41m\u001bSaving.....................\u001b[0m\n",
      "Train Epoch: 23 [544/562 (100.0%)]\tAverage loss: 0.487217\tTime: 3.202577\n",
      "Val  Epoch: 23 [71/71 (100.0%)]\tDice: 0.914045\tmIOU: 0.844357\tPrecision: 0.892077\tRecall: 0.942447\tF1_score: 0.914045\tTime: 0.673313\n",
      "\u001b[1m========== Test ==============\u001b[0m\n",
      "\u001b[44m\u001b[37mNormal\u001b[0m\n",
      "Test  Epoch: 23 [71/71 (100.0%)]\tDice: 0.899818\tmIOU: 0.822889\tPrecision: 0.860960\tRecall: 0.950232\tTime: 0.662330\n",
      "\u001b[43m\u001b[30mAbNormal\u001b[0m\n",
      "Test  Epoch: 23 [71/71 (100.0%)]\tDice: 0.912377\tmIOU: 0.840701\tPrecision: 0.884051\tRecall: 0.947981\tTime: 0.662380\n",
      "\u001b[42m\u001b[31mAverage\u001b[0m\n",
      "Test  Epoch: 23 [71/71 (100.0%)]\tDice: 0.906009\tmIOU: 0.831669\tPrecision: 0.872343\tRecall: 0.949122\tTime: 0.662428\n",
      "Train Epoch: 24 [544/562 (100.0%)]\tAverage loss: 0.479265\tTime: 3.247534\n",
      "Val  Epoch: 24 [71/71 (100.0%)]\tDice: 0.917665\tmIOU: 0.850596\tPrecision: 0.902267\tRecall: 0.939181\tF1_score: 0.917665\tTime: 0.705534\n",
      "\u001b[1m========== Test ==============\u001b[0m\n",
      "\u001b[44m\u001b[37mNormal\u001b[0m\n",
      "Test  Epoch: 24 [71/71 (100.0%)]\tDice: 0.905202\tmIOU: 0.831402\tPrecision: 0.873008\tRecall: 0.947838\tTime: 0.649755\n",
      "\u001b[43m\u001b[30mAbNormal\u001b[0m\n",
      "Test  Epoch: 24 [71/71 (100.0%)]\tDice: 0.913895\tmIOU: 0.843689\tPrecision: 0.891351\tRecall: 0.943365\tTime: 0.649804\n",
      "\u001b[42m\u001b[31mAverage\u001b[0m\n",
      "Test  Epoch: 24 [71/71 (100.0%)]\tDice: 0.909487\tmIOU: 0.837459\tPrecision: 0.882050\tRecall: 0.945633\tTime: 0.649851\n",
      "Train Epoch: 25 [544/562 (100.0%)]\tAverage loss: 0.471092\tTime: 3.195402\n",
      "Val  Epoch: 25 [71/71 (100.0%)]\tDice: 0.904213\tmIOU: 0.828625\tPrecision: 0.871235\tRecall: 0.946828\tF1_score: 0.904213\tTime: 0.741103\n",
      "\u001b[1m========== Test ==============\u001b[0m\n",
      "\u001b[44m\u001b[37mNormal\u001b[0m\n",
      "Test  Epoch: 25 [71/71 (100.0%)]\tDice: 0.883073\tmIOU: 0.796698\tPrecision: 0.834362\tRecall: 0.949827\tTime: 0.705893\n",
      "\u001b[43m\u001b[30mAbNormal\u001b[0m\n",
      "Test  Epoch: 25 [71/71 (100.0%)]\tDice: 0.899893\tmIOU: 0.820102\tPrecision: 0.861543\tRecall: 0.949283\tTime: 0.705945\n",
      "\u001b[42m\u001b[31mAverage\u001b[0m\n",
      "Test  Epoch: 25 [71/71 (100.0%)]\tDice: 0.891365\tmIOU: 0.808235\tPrecision: 0.847762\tRecall: 0.949559\tTime: 0.705992\n",
      "Train Epoch: 26 [544/562 (100.0%)]\tAverage loss: 0.471673\tTime: 3.320525\n",
      "Val  Epoch: 26 [71/71 (100.0%)]\tDice: 0.926332\tmIOU: 0.865141\tPrecision: 0.943995\tRecall: 0.913377\tF1_score: 0.926332\tTime: 0.666162\n",
      "\u001b[1m========== Test ==============\u001b[0m\n",
      "\u001b[44m\u001b[37mNormal\u001b[0m\n",
      "Test  Epoch: 26 [71/71 (100.0%)]\tDice: 0.917906\tmIOU: 0.851468\tPrecision: 0.920596\tRecall: 0.920430\tTime: 0.647085\n",
      "\u001b[43m\u001b[30mAbNormal\u001b[0m\n",
      "Test  Epoch: 26 [71/71 (100.0%)]\tDice: 0.920191\tmIOU: 0.856081\tPrecision: 0.936154\tRecall: 0.911452\tTime: 0.647140\n",
      "\u001b[42m\u001b[31mAverage\u001b[0m\n",
      "Test  Epoch: 26 [71/71 (100.0%)]\tDice: 0.919032\tmIOU: 0.853742\tPrecision: 0.928265\tRecall: 0.916005\tTime: 0.647189\n",
      "\u001b[41m\u001bSaving.....................\u001b[0m\n",
      "Train Epoch: 27 [544/562 (100.0%)]\tAverage loss: 0.453958\tTime: 3.271047\n",
      "Val  Epoch: 27 [71/71 (100.0%)]\tDice: 0.926239\tmIOU: 0.865313\tPrecision: 0.944062\tRecall: 0.913551\tF1_score: 0.926239\tTime: 0.715379\n",
      "\u001b[1m========== Test ==============\u001b[0m\n",
      "\u001b[44m\u001b[37mNormal\u001b[0m\n",
      "Test  Epoch: 27 [71/71 (100.0%)]\tDice: 0.921818\tmIOU: 0.858074\tPrecision: 0.924268\tRecall: 0.924350\tTime: 0.703073\n",
      "\u001b[43m\u001b[30mAbNormal\u001b[0m\n",
      "Test  Epoch: 27 [71/71 (100.0%)]\tDice: 0.922882\tmIOU: 0.860229\tPrecision: 0.935413\tRecall: 0.916331\tTime: 0.703123\n",
      "\u001b[42m\u001b[31mAverage\u001b[0m\n",
      "Test  Epoch: 27 [71/71 (100.0%)]\tDice: 0.922342\tmIOU: 0.859136\tPrecision: 0.929762\tRecall: 0.920397\tTime: 0.703170\n",
      "Train Epoch: 28 [544/562 (100.0%)]\tAverage loss: 0.454349\tTime: 3.212931\n",
      "Val  Epoch: 28 [71/71 (100.0%)]\tDice: 0.910346\tmIOU: 0.838052\tPrecision: 0.881061\tRecall: 0.947061\tF1_score: 0.910346\tTime: 0.670881\n",
      "\u001b[1m========== Test ==============\u001b[0m\n",
      "\u001b[44m\u001b[37mNormal\u001b[0m\n",
      "Test  Epoch: 28 [71/71 (100.0%)]\tDice: 0.896691\tmIOU: 0.816887\tPrecision: 0.851043\tRecall: 0.955294\tTime: 0.663899\n",
      "\u001b[43m\u001b[30mAbNormal\u001b[0m\n",
      "Test  Epoch: 28 [71/71 (100.0%)]\tDice: 0.908339\tmIOU: 0.833875\tPrecision: 0.873717\tRecall: 0.951509\tTime: 0.663949\n",
      "\u001b[42m\u001b[31mAverage\u001b[0m\n",
      "Test  Epoch: 28 [71/71 (100.0%)]\tDice: 0.902433\tmIOU: 0.825261\tPrecision: 0.862221\tRecall: 0.953429\tTime: 0.663996\n",
      "Train Epoch: 29 [544/562 (100.0%)]\tAverage loss: 0.447348\tTime: 3.267827\n",
      "Val  Epoch: 29 [71/71 (100.0%)]\tDice: 0.927010\tmIOU: 0.866573\tPrecision: 0.951720\tRecall: 0.907686\tF1_score: 0.927010\tTime: 0.685337\n",
      "\u001b[1m========== Test ==============\u001b[0m\n",
      "\u001b[44m\u001b[37mNormal\u001b[0m\n",
      "Test  Epoch: 29 [71/71 (100.0%)]\tDice: 0.923161\tmIOU: 0.860222\tPrecision: 0.933112\tRecall: 0.917809\tTime: 0.739705\n",
      "\u001b[43m\u001b[30mAbNormal\u001b[0m\n",
      "Test  Epoch: 29 [71/71 (100.0%)]\tDice: 0.924181\tmIOU: 0.862477\tPrecision: 0.944163\tRecall: 0.910544\tTime: 0.739755\n",
      "\u001b[42m\u001b[31mAverage\u001b[0m\n",
      "Test  Epoch: 29 [71/71 (100.0%)]\tDice: 0.923664\tmIOU: 0.861334\tPrecision: 0.938560\tRecall: 0.914228\tTime: 0.739803\n",
      "\u001b[41m\u001bSaving.....................\u001b[0m\n",
      "Train Epoch: 30 [544/562 (100.0%)]\tAverage loss: 0.434476\tTime: 3.230056\n",
      "Val  Epoch: 30 [71/71 (100.0%)]\tDice: 0.926733\tmIOU: 0.866203\tPrecision: 0.951399\tRecall: 0.907295\tF1_score: 0.926733\tTime: 0.704640\n",
      "\u001b[1m========== Test ==============\u001b[0m\n",
      "\u001b[44m\u001b[37mNormal\u001b[0m\n",
      "Test  Epoch: 30 [71/71 (100.0%)]\tDice: 0.920075\tmIOU: 0.855201\tPrecision: 0.929712\tRecall: 0.915217\tTime: 0.650450\n",
      "\u001b[43m\u001b[30mAbNormal\u001b[0m\n",
      "Test  Epoch: 30 [71/71 (100.0%)]\tDice: 0.924025\tmIOU: 0.862195\tPrecision: 0.943973\tRecall: 0.910531\tTime: 0.650501\n",
      "\u001b[42m\u001b[31mAverage\u001b[0m\n",
      "Test  Epoch: 30 [71/71 (100.0%)]\tDice: 0.922022\tmIOU: 0.858649\tPrecision: 0.936742\tRecall: 0.912907\tTime: 0.650549\n",
      "Train Epoch: 31 [544/562 (100.0%)]\tAverage loss: 0.431118\tTime: 3.251086\n",
      "Val  Epoch: 31 [71/71 (100.0%)]\tDice: 0.928713\tmIOU: 0.869410\tPrecision: 0.948777\tRecall: 0.913508\tF1_score: 0.928713\tTime: 0.678621\n",
      "\u001b[1m========== Test ==============\u001b[0m\n",
      "\u001b[44m\u001b[37mNormal\u001b[0m\n",
      "Test  Epoch: 31 [71/71 (100.0%)]\tDice: 0.923824\tmIOU: 0.861339\tPrecision: 0.929065\tRecall: 0.923012\tTime: 0.659873\n",
      "\u001b[43m\u001b[30mAbNormal\u001b[0m\n",
      "Test  Epoch: 31 [71/71 (100.0%)]\tDice: 0.925213\tmIOU: 0.864177\tPrecision: 0.941329\tRecall: 0.915343\tTime: 0.659924\n",
      "\u001b[42m\u001b[31mAverage\u001b[0m\n",
      "Test  Epoch: 31 [71/71 (100.0%)]\tDice: 0.924508\tmIOU: 0.862738\tPrecision: 0.935111\tRecall: 0.919232\tTime: 0.659972\n",
      "\u001b[41m\u001bSaving.....................\u001b[0m\n",
      "Train Epoch: 32 [544/562 (100.0%)]\tAverage loss: 0.421679\tTime: 3.257890\n",
      "Val  Epoch: 32 [71/71 (100.0%)]\tDice: 0.928281\tmIOU: 0.868714\tPrecision: 0.939896\tRecall: 0.921171\tF1_score: 0.928281\tTime: 0.696544\n",
      "\u001b[1m========== Test ==============\u001b[0m\n",
      "\u001b[44m\u001b[37mNormal\u001b[0m\n",
      "Test  Epoch: 32 [71/71 (100.0%)]\tDice: 0.919910\tmIOU: 0.854863\tPrecision: 0.915860\tRecall: 0.929009\tTime: 0.678100\n",
      "\u001b[43m\u001b[30mAbNormal\u001b[0m\n",
      "Test  Epoch: 32 [71/71 (100.0%)]\tDice: 0.922254\tmIOU: 0.858814\tPrecision: 0.930278\tRecall: 0.920011\tTime: 0.678152\n",
      "\u001b[42m\u001b[31mAverage\u001b[0m\n",
      "Test  Epoch: 32 [71/71 (100.0%)]\tDice: 0.921066\tmIOU: 0.856810\tPrecision: 0.922967\tRecall: 0.924573\tTime: 0.678200\n",
      "Train Epoch: 33 [544/562 (100.0%)]\tAverage loss: 0.422154\tTime: 3.300555\n",
      "Val  Epoch: 33 [71/71 (100.0%)]\tDice: 0.925415\tmIOU: 0.863616\tPrecision: 0.904555\tRecall: 0.951902\tF1_score: 0.925415\tTime: 0.731619\n",
      "\u001b[1m========== Test ==============\u001b[0m\n",
      "\u001b[44m\u001b[37mNormal\u001b[0m\n",
      "Test  Epoch: 33 [71/71 (100.0%)]\tDice: 0.911501\tmIOU: 0.841453\tPrecision: 0.873661\tRecall: 0.958743\tTime: 0.693675\n",
      "\u001b[43m\u001b[30mAbNormal\u001b[0m\n",
      "Test  Epoch: 33 [71/71 (100.0%)]\tDice: 0.919262\tmIOU: 0.852597\tPrecision: 0.892243\tRecall: 0.953587\tTime: 0.693727\n",
      "\u001b[42m\u001b[31mAverage\u001b[0m\n",
      "Test  Epoch: 33 [71/71 (100.0%)]\tDice: 0.915327\tmIOU: 0.846947\tPrecision: 0.882821\tRecall: 0.956201\tTime: 0.693775\n",
      "Train Epoch: 34 [544/562 (100.0%)]\tAverage loss: 0.411774\tTime: 3.239693\n",
      "Val  Epoch: 34 [71/71 (100.0%)]\tDice: 0.932136\tmIOU: 0.875394\tPrecision: 0.932643\tRecall: 0.935886\tF1_score: 0.932136\tTime: 0.688535\n",
      "\u001b[1m========== Test ==============\u001b[0m\n",
      "\u001b[44m\u001b[37mNormal\u001b[0m\n",
      "Test  Epoch: 34 [71/71 (100.0%)]\tDice: 0.920824\tmIOU: 0.857157\tPrecision: 0.904474\tRecall: 0.943415\tTime: 0.679740\n",
      "\u001b[43m\u001b[30mAbNormal\u001b[0m\n",
      "Test  Epoch: 34 [71/71 (100.0%)]\tDice: 0.925905\tmIOU: 0.864741\tPrecision: 0.922264\tRecall: 0.935107\tTime: 0.679790\n",
      "\u001b[42m\u001b[31mAverage\u001b[0m\n",
      "Test  Epoch: 34 [71/71 (100.0%)]\tDice: 0.923329\tmIOU: 0.860895\tPrecision: 0.913244\tRecall: 0.939320\tTime: 0.679838\n",
      "\u001b[41m\u001bSaving.....................\u001b[0m\n",
      "Train Epoch: 35 [544/562 (100.0%)]\tAverage loss: 0.405932\tTime: 3.305237\n",
      "Val  Epoch: 35 [71/71 (100.0%)]\tDice: 0.928176\tmIOU: 0.868906\tPrecision: 0.918714\tRecall: 0.943310\tF1_score: 0.928176\tTime: 0.656677\n",
      "\u001b[1m========== Test ==============\u001b[0m\n",
      "\u001b[44m\u001b[37mNormal\u001b[0m\n",
      "Test  Epoch: 35 [71/71 (100.0%)]\tDice: 0.919211\tmIOU: 0.855271\tPrecision: 0.891081\tRecall: 0.955922\tTime: 0.667076\n",
      "\u001b[43m\u001b[30mAbNormal\u001b[0m\n",
      "Test  Epoch: 35 [71/71 (100.0%)]\tDice: 0.925396\tmIOU: 0.863573\tPrecision: 0.910803\tRecall: 0.945755\tTime: 0.667126\n",
      "\u001b[42m\u001b[31mAverage\u001b[0m\n",
      "Test  Epoch: 35 [71/71 (100.0%)]\tDice: 0.922260\tmIOU: 0.859364\tPrecision: 0.900803\tRecall: 0.950910\tTime: 0.667174\n",
      "Train Epoch: 36 [544/562 (100.0%)]\tAverage loss: 0.398561\tTime: 3.250891\n",
      "Val  Epoch: 36 [71/71 (100.0%)]\tDice: 0.927368\tmIOU: 0.867486\tPrecision: 0.923567\tRecall: 0.936043\tF1_score: 0.927368\tTime: 0.714331\n",
      "\u001b[1m========== Test ==============\u001b[0m\n",
      "\u001b[44m\u001b[37mNormal\u001b[0m\n",
      "Test  Epoch: 36 [71/71 (100.0%)]\tDice: 0.920194\tmIOU: 0.855564\tPrecision: 0.898869\tRecall: 0.947647\tTime: 0.664593\n",
      "\u001b[43m\u001b[30mAbNormal\u001b[0m\n",
      "Test  Epoch: 36 [71/71 (100.0%)]\tDice: 0.922311\tmIOU: 0.858325\tPrecision: 0.913443\tRecall: 0.936624\tTime: 0.664643\n",
      "\u001b[42m\u001b[31mAverage\u001b[0m\n",
      "Test  Epoch: 36 [71/71 (100.0%)]\tDice: 0.921238\tmIOU: 0.856925\tPrecision: 0.906053\tRecall: 0.942213\tTime: 0.664690\n",
      "Train Epoch: 37 [544/562 (100.0%)]\tAverage loss: 0.396357\tTime: 3.282883\n",
      "Val  Epoch: 37 [71/71 (100.0%)]\tDice: 0.934028\tmIOU: 0.878972\tPrecision: 0.946770\tRecall: 0.925797\tF1_score: 0.934028\tTime: 0.740344\n",
      "\u001b[1m========== Test ==============\u001b[0m\n",
      "\u001b[44m\u001b[37mNormal\u001b[0m\n",
      "Test  Epoch: 37 [71/71 (100.0%)]\tDice: 0.927541\tmIOU: 0.868221\tPrecision: 0.924988\tRecall: 0.934755\tTime: 0.725665\n",
      "\u001b[43m\u001b[30mAbNormal\u001b[0m\n",
      "Test  Epoch: 37 [71/71 (100.0%)]\tDice: 0.929845\tmIOU: 0.872008\tPrecision: 0.937154\tRecall: 0.927877\tTime: 0.725719\n",
      "\u001b[42m\u001b[31mAverage\u001b[0m\n",
      "Test  Epoch: 37 [71/71 (100.0%)]\tDice: 0.928677\tmIOU: 0.870088\tPrecision: 0.930985\tRecall: 0.931364\tTime: 0.725768\n",
      "\u001b[41m\u001bSaving.....................\u001b[0m\n",
      "Train Epoch: 38 [544/562 (100.0%)]\tAverage loss: 0.390830\tTime: 3.287496\n",
      "Val  Epoch: 38 [71/71 (100.0%)]\tDice: 0.930488\tmIOU: 0.872836\tPrecision: 0.960408\tRecall: 0.906504\tF1_score: 0.930488\tTime: 0.667111\n",
      "\u001b[1m========== Test ==============\u001b[0m\n",
      "\u001b[44m\u001b[37mNormal\u001b[0m\n",
      "Test  Epoch: 38 [71/71 (100.0%)]\tDice: 0.929872\tmIOU: 0.871863\tPrecision: 0.945801\tRecall: 0.918298\tTime: 0.662348\n",
      "\u001b[43m\u001b[30mAbNormal\u001b[0m\n",
      "Test  Epoch: 38 [71/71 (100.0%)]\tDice: 0.927324\tmIOU: 0.868171\tPrecision: 0.953172\tRecall: 0.908128\tTime: 0.662398\n",
      "\u001b[42m\u001b[31mAverage\u001b[0m\n",
      "Test  Epoch: 38 [71/71 (100.0%)]\tDice: 0.928616\tmIOU: 0.870043\tPrecision: 0.949435\tRecall: 0.913285\tTime: 0.662446\n",
      "Train Epoch: 39 [544/562 (100.0%)]\tAverage loss: 0.386044\tTime: 3.286617\n",
      "Val  Epoch: 39 [71/71 (100.0%)]\tDice: 0.926690\tmIOU: 0.866047\tPrecision: 0.966106\tRecall: 0.893904\tF1_score: 0.926690\tTime: 0.691198\n",
      "\u001b[1m========== Test ==============\u001b[0m\n",
      "\u001b[44m\u001b[37mNormal\u001b[0m\n",
      "Test  Epoch: 39 [71/71 (100.0%)]\tDice: 0.923980\tmIOU: 0.861304\tPrecision: 0.951641\tRecall: 0.901480\tTime: 0.676505\n",
      "\u001b[43m\u001b[30mAbNormal\u001b[0m\n",
      "Test  Epoch: 39 [71/71 (100.0%)]\tDice: 0.922070\tmIOU: 0.859221\tPrecision: 0.958066\tRecall: 0.893961\tTime: 0.676554\n",
      "\u001b[42m\u001b[31mAverage\u001b[0m\n",
      "Test  Epoch: 39 [71/71 (100.0%)]\tDice: 0.923038\tmIOU: 0.860277\tPrecision: 0.954808\tRecall: 0.897773\tTime: 0.676600\n",
      "Train Epoch: 40 [544/562 (100.0%)]\tAverage loss: 0.382398\tTime: 3.240821\n",
      "Val  Epoch: 40 [71/71 (100.0%)]\tDice: 0.933190\tmIOU: 0.877771\tPrecision: 0.935426\tRecall: 0.935837\tF1_score: 0.933190\tTime: 0.752897\n",
      "\u001b[1m========== Test ==============\u001b[0m\n",
      "\u001b[44m\u001b[37mNormal\u001b[0m\n",
      "Test  Epoch: 40 [71/71 (100.0%)]\tDice: 0.927310\tmIOU: 0.868661\tPrecision: 0.912390\tRecall: 0.948288\tTime: 0.680548\n",
      "\u001b[43m\u001b[30mAbNormal\u001b[0m\n",
      "Test  Epoch: 40 [71/71 (100.0%)]\tDice: 0.929354\tmIOU: 0.870732\tPrecision: 0.925906\tRecall: 0.937905\tTime: 0.680597\n",
      "\u001b[42m\u001b[31mAverage\u001b[0m\n",
      "Test  Epoch: 40 [71/71 (100.0%)]\tDice: 0.928318\tmIOU: 0.869682\tPrecision: 0.919053\tRecall: 0.943170\tTime: 0.680644\n",
      "Train Epoch: 41 [544/562 (100.0%)]\tAverage loss: 0.372638\tTime: 3.290354\n",
      "Val  Epoch: 41 [71/71 (100.0%)]\tDice: 0.934308\tmIOU: 0.879476\tPrecision: 0.947487\tRecall: 0.925718\tF1_score: 0.934308\tTime: 0.662965\n",
      "\u001b[1m========== Test ==============\u001b[0m\n",
      "\u001b[44m\u001b[37mNormal\u001b[0m\n",
      "Test  Epoch: 41 [71/71 (100.0%)]\tDice: 0.932010\tmIOU: 0.875554\tPrecision: 0.930942\tRecall: 0.937243\tTime: 0.719076\n",
      "\u001b[43m\u001b[30mAbNormal\u001b[0m\n",
      "Test  Epoch: 41 [71/71 (100.0%)]\tDice: 0.929638\tmIOU: 0.871672\tPrecision: 0.937214\tRecall: 0.927428\tTime: 0.719130\n",
      "\u001b[42m\u001b[31mAverage\u001b[0m\n",
      "Test  Epoch: 41 [71/71 (100.0%)]\tDice: 0.930840\tmIOU: 0.873640\tPrecision: 0.934034\tRecall: 0.932404\tTime: 0.719178\n",
      "\u001b[41m\u001bSaving.....................\u001b[0m\n",
      "Train Epoch: 42 [544/562 (100.0%)]\tAverage loss: 0.371205\tTime: 3.367822\n",
      "Val  Epoch: 42 [71/71 (100.0%)]\tDice: 0.925336\tmIOU: 0.864631\tPrecision: 0.920945\tRecall: 0.935444\tF1_score: 0.925336\tTime: 0.663749\n",
      "\u001b[1m========== Test ==============\u001b[0m\n",
      "\u001b[44m\u001b[37mNormal\u001b[0m\n",
      "Test  Epoch: 42 [71/71 (100.0%)]\tDice: 0.908807\tmIOU: 0.837940\tPrecision: 0.886231\tRecall: 0.939606\tTime: 0.663706\n",
      "\u001b[43m\u001b[30mAbNormal\u001b[0m\n",
      "Test  Epoch: 42 [71/71 (100.0%)]\tDice: 0.922699\tmIOU: 0.859028\tPrecision: 0.913250\tRecall: 0.938288\tTime: 0.663756\n",
      "\u001b[42m\u001b[31mAverage\u001b[0m\n",
      "Test  Epoch: 42 [71/71 (100.0%)]\tDice: 0.915655\tmIOU: 0.848335\tPrecision: 0.899550\tRecall: 0.938956\tTime: 0.663801\n",
      "Train Epoch: 43 [544/562 (100.0%)]\tAverage loss: 0.365850\tTime: 3.219365\n",
      "Val  Epoch: 43 [71/71 (100.0%)]\tDice: 0.935952\tmIOU: 0.882082\tPrecision: 0.937115\tRecall: 0.938929\tF1_score: 0.935952\tTime: 0.673674\n",
      "\u001b[1m========== Test ==============\u001b[0m\n",
      "\u001b[44m\u001b[37mNormal\u001b[0m\n",
      "Test  Epoch: 43 [71/71 (100.0%)]\tDice: 0.929378\tmIOU: 0.871635\tPrecision: 0.914042\tRecall: 0.949603\tTime: 0.666028\n",
      "\u001b[43m\u001b[30mAbNormal\u001b[0m\n",
      "Test  Epoch: 43 [71/71 (100.0%)]\tDice: 0.931446\tmIOU: 0.874223\tPrecision: 0.927840\tRecall: 0.940187\tTime: 0.666077\n",
      "\u001b[42m\u001b[31mAverage\u001b[0m\n",
      "Test  Epoch: 43 [71/71 (100.0%)]\tDice: 0.930397\tmIOU: 0.872911\tPrecision: 0.920844\tRecall: 0.944961\tTime: 0.666124\n",
      "\u001b[41m\u001bSaving.....................\u001b[0m\n",
      "Train Epoch: 44 [544/562 (100.0%)]\tAverage loss: 0.360459\tTime: 3.219798\n",
      "Val  Epoch: 44 [71/71 (100.0%)]\tDice: 0.935123\tmIOU: 0.881111\tPrecision: 0.948097\tRecall: 0.927011\tF1_score: 0.935123\tTime: 0.733453\n",
      "\u001b[1m========== Test ==============\u001b[0m\n",
      "\u001b[44m\u001b[37mNormal\u001b[0m\n",
      "Test  Epoch: 44 [71/71 (100.0%)]\tDice: 0.930822\tmIOU: 0.874084\tPrecision: 0.927855\tRecall: 0.938749\tTime: 0.725405\n",
      "\u001b[43m\u001b[30mAbNormal\u001b[0m\n",
      "Test  Epoch: 44 [71/71 (100.0%)]\tDice: 0.930129\tmIOU: 0.872320\tPrecision: 0.937446\tRecall: 0.928020\tTime: 0.725457\n",
      "\u001b[42m\u001b[31mAverage\u001b[0m\n",
      "Test  Epoch: 44 [71/71 (100.0%)]\tDice: 0.930481\tmIOU: 0.873214\tPrecision: 0.932583\tRecall: 0.933460\tTime: 0.725507\n",
      "Train Epoch: 45 [544/562 (100.0%)]\tAverage loss: 0.353673\tTime: 3.278169\n",
      "Val  Epoch: 45 [71/71 (100.0%)]\tDice: 0.933436\tmIOU: 0.877923\tPrecision: 0.938664\tRecall: 0.932679\tF1_score: 0.933436\tTime: 0.699965\n",
      "\u001b[1m========== Test ==============\u001b[0m\n",
      "\u001b[44m\u001b[37mNormal\u001b[0m\n",
      "Test  Epoch: 45 [71/71 (100.0%)]\tDice: 0.927671\tmIOU: 0.868716\tPrecision: 0.916601\tRecall: 0.943791\tTime: 0.678595\n",
      "\u001b[43m\u001b[30mAbNormal\u001b[0m\n",
      "Test  Epoch: 45 [71/71 (100.0%)]\tDice: 0.927976\tmIOU: 0.868409\tPrecision: 0.927506\tRecall: 0.933382\tTime: 0.678646\n",
      "\u001b[42m\u001b[31mAverage\u001b[0m\n",
      "Test  Epoch: 45 [71/71 (100.0%)]\tDice: 0.927821\tmIOU: 0.868565\tPrecision: 0.921977\tRecall: 0.938660\tTime: 0.678693\n",
      "Train Epoch: 46 [544/562 (100.0%)]\tAverage loss: 0.927894\tTime: 3.366126\n",
      "Val  Epoch: 46 [71/71 (100.0%)]\tDice: 0.550876\tmIOU: 0.419532\tPrecision: 0.914830\tRecall: 0.427875\tF1_score: 0.550876\tTime: 0.692831\n",
      "\u001b[1m========== Test ==============\u001b[0m\n",
      "\u001b[44m\u001b[37mNormal\u001b[0m\n",
      "Test  Epoch: 46 [71/71 (100.0%)]\tDice: 0.455100\tmIOU: 0.336715\tPrecision: 0.851768\tRecall: 0.349181\tTime: 0.691559\n",
      "\u001b[43m\u001b[30mAbNormal\u001b[0m\n",
      "Test  Epoch: 46 [71/71 (100.0%)]\tDice: 0.612687\tmIOU: 0.481528\tPrecision: 0.910663\tRecall: 0.496217\tTime: 0.691611\n",
      "\u001b[42m\u001b[31mAverage\u001b[0m\n",
      "Test  Epoch: 46 [71/71 (100.0%)]\tDice: 0.532784\tmIOU: 0.408102\tPrecision: 0.880801\tRecall: 0.421663\tTime: 0.691660\n",
      "Train Epoch: 47 [544/562 (100.0%)]\tAverage loss: 0.789714\tTime: 3.292465\n",
      "Val  Epoch: 47 [71/71 (100.0%)]\tDice: 0.838033\tmIOU: 0.728844\tPrecision: 0.852697\tRecall: 0.836530\tF1_score: 0.838033\tTime: 0.718086\n",
      "\u001b[1m========== Test ==============\u001b[0m\n",
      "\u001b[44m\u001b[37mNormal\u001b[0m\n",
      "Test  Epoch: 47 [71/71 (100.0%)]\tDice: 0.806022\tmIOU: 0.684398\tPrecision: 0.800693\tRecall: 0.829268\tTime: 0.675082\n",
      "\u001b[43m\u001b[30mAbNormal\u001b[0m\n",
      "Test  Epoch: 47 [71/71 (100.0%)]\tDice: 0.855763\tmIOU: 0.752780\tPrecision: 0.874385\tRecall: 0.854935\tTime: 0.675133\n",
      "\u001b[42m\u001b[31mAverage\u001b[0m\n",
      "Test  Epoch: 47 [71/71 (100.0%)]\tDice: 0.830542\tmIOU: 0.718108\tPrecision: 0.837020\tRecall: 0.841921\tTime: 0.675181\n",
      "Train Epoch: 48 [544/562 (100.0%)]\tAverage loss: 0.504609\tTime: 3.266851\n",
      "Val  Epoch: 48 [71/71 (100.0%)]\tDice: 0.876411\tmIOU: 0.784391\tPrecision: 0.938111\tRecall: 0.829143\tF1_score: 0.876411\tTime: 0.700455\n",
      "\u001b[1m========== Test ==============\u001b[0m\n",
      "\u001b[44m\u001b[37mNormal\u001b[0m\n",
      "Test  Epoch: 48 [71/71 (100.0%)]\tDice: 0.862638\tmIOU: 0.762594\tPrecision: 0.915050\tRecall: 0.824644\tTime: 0.696099\n",
      "\u001b[43m\u001b[30mAbNormal\u001b[0m\n",
      "Test  Epoch: 48 [71/71 (100.0%)]\tDice: 0.882493\tmIOU: 0.794857\tPrecision: 0.933419\tRecall: 0.846497\tTime: 0.696150\n",
      "\u001b[42m\u001b[31mAverage\u001b[0m\n",
      "Test  Epoch: 48 [71/71 (100.0%)]\tDice: 0.872426\tmIOU: 0.778498\tPrecision: 0.924105\tRecall: 0.835416\tTime: 0.696198\n",
      "Train Epoch: 49 [544/562 (100.0%)]\tAverage loss: 0.442640\tTime: 3.234857\n",
      "Val  Epoch: 49 [71/71 (100.0%)]\tDice: 0.906145\tmIOU: 0.831796\tPrecision: 0.914290\tRecall: 0.905289\tF1_score: 0.906145\tTime: 0.680522\n",
      "\u001b[1m========== Test ==============\u001b[0m\n",
      "\u001b[44m\u001b[37mNormal\u001b[0m\n",
      "Test  Epoch: 49 [71/71 (100.0%)]\tDice: 0.890066\tmIOU: 0.806987\tPrecision: 0.883597\tRecall: 0.908113\tTime: 0.683661\n",
      "\u001b[43m\u001b[30mAbNormal\u001b[0m\n",
      "Test  Epoch: 49 [71/71 (100.0%)]\tDice: 0.905800\tmIOU: 0.830324\tPrecision: 0.905180\tRecall: 0.913281\tTime: 0.683714\n",
      "\u001b[42m\u001b[31mAverage\u001b[0m\n",
      "Test  Epoch: 49 [71/71 (100.0%)]\tDice: 0.897822\tmIOU: 0.818491\tPrecision: 0.894237\tRecall: 0.910660\tTime: 0.683762\n",
      "Train Epoch: 50 [544/562 (100.0%)]\tAverage loss: 0.418233\tTime: 3.281310\n",
      "Val  Epoch: 50 [71/71 (100.0%)]\tDice: 0.913515\tmIOU: 0.843937\tPrecision: 0.942545\tRecall: 0.891748\tF1_score: 0.913515\tTime: 0.668039\n",
      "\u001b[1m========== Test ==============\u001b[0m\n",
      "\u001b[44m\u001b[37mNormal\u001b[0m\n",
      "Test  Epoch: 50 [71/71 (100.0%)]\tDice: 0.902014\tmIOU: 0.824953\tPrecision: 0.917271\tRecall: 0.894223\tTime: 0.660278\n",
      "\u001b[43m\u001b[30mAbNormal\u001b[0m\n",
      "Test  Epoch: 50 [71/71 (100.0%)]\tDice: 0.910901\tmIOU: 0.840520\tPrecision: 0.933891\tRecall: 0.896918\tTime: 0.660326\n",
      "\u001b[42m\u001b[31mAverage\u001b[0m\n",
      "Test  Epoch: 50 [71/71 (100.0%)]\tDice: 0.906395\tmIOU: 0.832627\tPrecision: 0.925464\tRecall: 0.895551\tTime: 0.660373\n",
      "Train Epoch: 51 [544/562 (100.0%)]\tAverage loss: 0.392366\tTime: 3.209495\n",
      "Val  Epoch: 51 [71/71 (100.0%)]\tDice: 0.922137\tmIOU: 0.857916\tPrecision: 0.937046\tRecall: 0.912119\tF1_score: 0.922137\tTime: 0.718797\n",
      "\u001b[1m========== Test ==============\u001b[0m\n",
      "\u001b[44m\u001b[37mNormal\u001b[0m\n",
      "Test  Epoch: 51 [71/71 (100.0%)]\tDice: 0.909446\tmIOU: 0.837414\tPrecision: 0.909246\tRecall: 0.915991\tTime: 0.698449\n",
      "\u001b[43m\u001b[30mAbNormal\u001b[0m\n",
      "Test  Epoch: 51 [71/71 (100.0%)]\tDice: 0.918257\tmIOU: 0.852176\tPrecision: 0.928417\tRecall: 0.914965\tTime: 0.698498\n",
      "\u001b[42m\u001b[31mAverage\u001b[0m\n",
      "Test  Epoch: 51 [71/71 (100.0%)]\tDice: 0.913789\tmIOU: 0.844691\tPrecision: 0.918697\tRecall: 0.915485\tTime: 0.698544\n",
      "Train Epoch: 52 [544/562 (100.0%)]\tAverage loss: 0.376493\tTime: 3.261153\n",
      "Val  Epoch: 52 [71/71 (100.0%)]\tDice: 0.922524\tmIOU: 0.858574\tPrecision: 0.922364\tRecall: 0.927332\tF1_score: 0.922524\tTime: 0.692016\n",
      "\u001b[1m========== Test ==============\u001b[0m\n",
      "\u001b[44m\u001b[37mNormal\u001b[0m\n",
      "Test  Epoch: 52 [71/71 (100.0%)]\tDice: 0.910489\tmIOU: 0.839224\tPrecision: 0.893135\tRecall: 0.935048\tTime: 0.688778\n",
      "\u001b[43m\u001b[30mAbNormal\u001b[0m\n",
      "Test  Epoch: 52 [71/71 (100.0%)]\tDice: 0.918283\tmIOU: 0.851399\tPrecision: 0.914347\tRecall: 0.927678\tTime: 0.688830\n",
      "\u001b[42m\u001b[31mAverage\u001b[0m\n",
      "Test  Epoch: 52 [71/71 (100.0%)]\tDice: 0.914331\tmIOU: 0.845226\tPrecision: 0.903592\tRecall: 0.931415\tTime: 0.688878\n",
      "Train Epoch: 53 [544/562 (100.0%)]\tAverage loss: 0.363875\tTime: 3.363587\n",
      "Val  Epoch: 53 [71/71 (100.0%)]\tDice: 0.921221\tmIOU: 0.856268\tPrecision: 0.914287\tRecall: 0.933089\tF1_score: 0.921221\tTime: 0.699886\n",
      "\u001b[1m========== Test ==============\u001b[0m\n",
      "\u001b[44m\u001b[37mNormal\u001b[0m\n",
      "Test  Epoch: 53 [71/71 (100.0%)]\tDice: 0.909109\tmIOU: 0.836954\tPrecision: 0.884060\tRecall: 0.942418\tTime: 0.699159\n",
      "\u001b[43m\u001b[30mAbNormal\u001b[0m\n",
      "Test  Epoch: 53 [71/71 (100.0%)]\tDice: 0.916852\tmIOU: 0.848798\tPrecision: 0.906287\tRecall: 0.933192\tTime: 0.699211\n",
      "\u001b[42m\u001b[31mAverage\u001b[0m\n",
      "Test  Epoch: 53 [71/71 (100.0%)]\tDice: 0.912926\tmIOU: 0.842792\tPrecision: 0.895017\tRecall: 0.937870\tTime: 0.699259\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "from eval import validation, test\n",
    "from build import build\n",
    "import argparse\n",
    "import yaml\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "def train_epoch(model, device, train_loader, optimizer, epoch, Dice_loss, BCE_loss, args):\n",
    "    t = time.time()\n",
    "    model.train()\n",
    "    loss_accumulator = []\n",
    "    for batch_idx, (data, target, _) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        for k in range(0, data.shape[0], args.mini_batch):\n",
    "            data_input = data[k:k + args.mini_batch]\n",
    "            target_input = target[k:k + args.mini_batch]\n",
    "            output = model(data_input)\n",
    "            loss = Dice_loss(output, target_input) + BCE_loss(torch.sigmoid(output), target_input)\n",
    "            loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_accumulator.append(loss.item())\n",
    "        if batch_idx + 1 < len(train_loader):\n",
    "            print(\n",
    "                \"\\rTrain Epoch: {} [{}/{} ({:.1f}%)]\\tLoss: {:.6f}\\tTime: {:.6f}\".format(\n",
    "                    epoch, (batch_idx + 1) * len(data), len(train_loader.dataset), 100.0 * (batch_idx + 1) / len(train_loader),\n",
    "                    loss.item(), time.time() - t, ), end=\"\", )\n",
    "        else:\n",
    "            print(\n",
    "                \"\\rTrain Epoch: {} [{}/{} ({:.1f}%)]\\tAverage loss: {:.6f}\\tTime: {:.6f}\".format(\n",
    "                    epoch, (batch_idx + 1) * len(data), len(train_loader.dataset), 100.0 * (batch_idx + 1) / len(train_loader),\n",
    "                    np.mean(loss_accumulator), time.time() - t, ) )\n",
    "\n",
    "    return np.mean(loss_accumulator)\n",
    "\n",
    "\n",
    "\n",
    "def train(args):\n",
    "\n",
    "    if not os.path.exists(\"./Trained models\"):\n",
    "        os.makedirs(\"./Trained models\")\n",
    "\n",
    "    ( device, train_dataloader, val_dataloader, test_dataloader,\n",
    "     perf, model, optimizer, checkpoint, scheduler, loss_fun) = build(args)\n",
    "\n",
    "    prev_best_test = checkpoint[\"test_measure_mean\"]\n",
    "    print(\"best test:\", prev_best_test, \"epoch:\", checkpoint[\"epoch\"])\n",
    "\n",
    "    for epoch in range(1, args.epochs + 1):\n",
    "        try:\n",
    "            loss = train_epoch(\n",
    "                model, device, train_dataloader, optimizer, epoch, loss_fun[\"Dice_loss\"],\\\n",
    "                      loss_fun[\"BCE_loss\"], args\n",
    "            )\n",
    "            val_measure_mean, val_measure_std = validation(\n",
    "                model, device, val_dataloader, epoch, perf,\"Val\"\n",
    "            )\n",
    "            test_measure_mean, test_measure_std = test(\n",
    "                model, device, test_dataloader, epoch, perf,\"Test\"\n",
    "            )\n",
    "        except KeyboardInterrupt:\n",
    "            print(\"Training interrupted by user\")\n",
    "            sys.exit(0)\n",
    "        if args.lrs == \"true\":\n",
    "            if args.type_lr == \"LROnP\":\n",
    "                scheduler.step(test_measure_mean)\n",
    "            else:\n",
    "                scheduler.step()\n",
    "        if prev_best_test == None or val_measure_mean > prev_best_test:\n",
    "            print(\"\\033[41m\\033Saving.....................\\033[0m\")\n",
    "            torch.save(\n",
    "                {\n",
    "                    \"epoch\": epoch,\n",
    "                    \"model_state_dict\": model.state_dict()\n",
    "                    if args.mgpu == \"false\"\n",
    "                    else model.module.state_dict(),\n",
    "                    \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "                    \"scheduler\":scheduler.state_dict(),\n",
    "                    \"loss\": loss,\n",
    "                    \"test_measure_mean\": test_measure_mean,\n",
    "                    \"test_measure_std\": test_measure_std,\n",
    "                },\n",
    "                f\"./Trained models/\" + args.dataset + \"_\" + args.model_name[\"version\"] + \".pt\",\n",
    "            )\n",
    "            prev_best_test = val_measure_mean\n",
    "\n",
    "\n",
    "def main(args):\n",
    "    train(args)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # ng dn n tp YAML\n",
    "    yaml_file = \"/home/bigdata/Documents/TND_Modeling/config.yaml\"\n",
    "\n",
    "    # c tp YAML\n",
    "    with open(yaml_file, \"r\") as file:\n",
    "        yaml_data = yaml.safe_load(file)\n",
    "\n",
    "    # Chuyn i d liu YAML thnh i tng namespace\n",
    "    args = argparse.Namespace(**yaml_data)\n",
    "    main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medical",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
